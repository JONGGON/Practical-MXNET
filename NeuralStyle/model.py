import cv2import mxnet as mximport mxnet.autograd as autogradimport mxnet.gluon as gluonimport mxnet.ndarray as ndimport numpy as npfrom mxboard import SummaryWriterfrom tqdm import *from VGG import get_vggfrom data_preprocessing import data_preprocessingdef showimage(image):    r, g, b = nd.split(image[0], axis=0, num_outputs=3)    # Denormalization by JG    r = nd.multiply(r, 0.229) + 0.485    g = nd.multiply(g, 0.224) + 0.456    b = nd.multiply(b, 0.225) + 0.406    image = nd.concat(r, g, b, dim=0)    image = nd.transpose(image, axes=(1, 2, 0))    image = nd.clip(image, a_min=0, a_max=1)    image = nd.multiply(image, 255)    image = nd.clip(image, a_min=0, a_max=255).astype('uint8')    # opencv로 보여주기 이미지    numpyimage = image.asnumpy()    numpyimage = cv2.cvtColor(numpyimage, cv2.COLOR_RGB2BGR)    cv2.imwrite("result.png", numpyimage)    # mxboard에 그릴 이미지 - Image is one of the following formats: (H, W), (C, H, W), (N, C, H, W).    mxboardimage = nd.transpose(image, axes=(2, 0, 1))    return mxboardimagedef neuralstyle(epoch=100, show_period=100, optimizer="adam", image_size=(), learning_rate=0.1, content_image=None,                style_image=None, content_a=None, style_b=None, initial_noise_image=None, ctx=mx.gpu(0),                mxboard_savepath="mxboard"):    # 1. Data Preprocessing and noise data    content_image, style_image, noise = data_preprocessing(content_image=content_image, style_image=style_image,                                                           image_size=image_size, ctx=ctx)    noise_image = gluon.Parameter('noise', grad_req="write", shape=content_image.shape)    noise_image.initialize(ctx=ctx)    # initializing noise image below values    if initial_noise_image == "content_image":        noise_image.set_data(content_image)    elif initial_noise_image == "style_image":        noise_image.set_data(style_image)    else:        noise_image.set_data(noise)    # 2. Predefined VGG19 Network    # style : cov1_1 ,cov2_1 ,cov3_1 ,cov4_1 ,cov5_1    select_style = [1, 6, 11, 20, 29]    # content : conv4_2    select_content = [22]    select = select_style + select_content    weighting_factors = nd.divide(nd.ones(shape=np.shape(select_style), ctx=ctx), len(select_style))    vgg19 = get_vgg(select=select, num_layers=19, pretrained=True, batch_norm=False, ctx=ctx)    '''    To visualize a Gluon model built using HybridBlocks,     users must first call hybridize(), initialize(), and forward() functions     to generate a graph symbol which will be used later to plot network structures.        from mxnet.gluon import nn    from mxboard import SummaryWriter    import mxnet as mx    net = nn.HybridSequential()    with net.name_scope():    net.add(nn.Dense(128, activation='relu'))    net.add(nn.Dense(64, activation='relu'))    net.add(nn.Dense(10))    # The following three lines hybridize the network, initialize the parameters,    # and run forward pass once to generate a symbol which will be used later    # for plotting the network.    net.hybridize()    net.initialize()    net.forward(mx.nd.ones((1,)))        with SummaryWriter(logdir='./logs') as sw:        sw.add_graph(net)        '''    vgg19.hybridize()    summary = SummaryWriter(logdir=mxboard_savepath, max_queue=10, flush_secs=10)    # 3 x 224 x 224 보단 커야함 - 너무 크면 out of memory 오류 발생    # 그래프 그리기 - 한번 forward 해줘야 함    vgg19.forward(mx.nd.ones((1, 3, 512, 512), ctx=ctx))    summary.add_graph(vgg19)    # optimizer    content_loss = gluon.loss.L2Loss()    style_loss = gluon.loss.L2Loss()    trainer = gluon.Trainer([noise_image], optimizer, {"learning_rate": learning_rate})    # 3 learning    for i in tqdm(range(1, epoch + 1, 1)):        c_loss = nd.array([0, ], ctx=ctx)        s_loss = nd.array([0, ], ctx=ctx)        with autograd.record(train_mode=True):  # Location is very important            content = vgg19(content_image)            noise = vgg19(noise_image.data())            style = vgg19(style_image)            for j, (n, c, s) in enumerate(zip(noise, content, style), start=1):                batch_size, filter, height, width = n.shape                # (1)compute style lose                # using cov1_1 ,cov2_1 ,cov3_1 ,cov4_1 ,cov5_1                if j < len(select):                    # reshape                    n = n.reshape((-1, height * width))                    s = s.reshape((-1, height * width))                    N = filter                    M = height * width                    '''                    The style and noise size can be different                    -> This is because there are only the filter * filter(channel*channel) is left                    as a result of the gram matrix                    '''                    # gram_matrix                    n = nd.dot(n, n, transpose_a=False, transpose_b=True)  # (filter, filter)                    s = nd.dot(s, s, transpose_a=False, transpose_b=True)  # (filter, filter                    # autograd.record() is not supporting the += operator                    s_loss = s_loss + nd.mean(nd.multiply(nd.divide(style_loss(n, s), 2 * N * M),                                                          weighting_factors[j - 1]))  # nd.mean((filter,))                    # s_loss = s_loss + nd.mean(nd.multiply(nd.divide(style_loss(n, s), 2 * (N*N) * (M*M)), weighting_factors[j - 1])) # it is too small because of the square of N,M                # (2)compute content lose                # using conv4_2                if j == len(select):                    # reshape                    n = n.reshape((-1, height * width))                    c = c.reshape((-1, height * width))                    '''                    If you do not want the size of the content image and the noise image to be the same,                    you should work with c equal to n. i did not do anything here.                     Therefore, the content size and noise size should be the same.                     '''                    c_loss = content_loss(n, c)                    c_loss = nd.mean(c_loss)            c_loss = nd.multiply(c_loss, content_a)            s_loss = nd.multiply(s_loss, style_b)            loss = c_loss + s_loss        loss.backward()        trainer.step(1, ignore_stale_grad=True)        summary.add_scalar("cost", loss.asscalar(), i)        print(" epoch : {} , cost : {}".format(i, loss.asscalar()))        # saving image        if i % show_period == 0:            concated_image = nd.concat(content_image, style_image, noise_image.data(), dim=-1)            mxboardimage = showimage(concated_image)            summary.add_image("result", mxboardimage, global_step=i)if __name__ == "__main__":    content_image = "content/tiger1.jpg"    style_image = "style/rain_princess.jpg"    initial_noise_image = "content_image"    image_size = (512, 512)    neuralstyle(epoch=1000, show_period=100, optimizer="adam", image_size=image_size, learning_rate=0.1,                content_image=content_image, style_image=style_image, content_a=1, style_b=1000,                initial_noise_image=initial_noise_image, ctx=mx.cpu(0), mxboard_savepath="mxboard")else:    print("Imported")